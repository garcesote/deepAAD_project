# evluating different mdl sizes and complexities
global_path: 'C:/Users/jaulab/Desktop/deepAAD_project'
global_data_path: 'C:/Users/jaulab/Desktop/AAD/Data'
# global_path: 'C:/Users/garcia.127407/Desktop/DNN_AAD/deepAAD_project'
# global_data_path: 'D:\igarcia\AAD_Data'

exp_name: 'embed_size'

runs:
  
  # - model: 'Conformer' # modelo normal
  #   train_params:
  #     batch_size: 128              
  #     max_epoch: 200              
  #     lr: 1e-06
  #     weight_decay: 1e-04                     
  #     early_stopping_patience: 5
  #     scheduler_patience: 2
  #   dataset_params:
  #     window_len: 50  
  #     hop: 1          
  #     filt: False       
  #     fixed: False      
  #     rnd_trials: False   
  #     unit_output: True
  #   model_params:
  #     mlp_ratio: 2
  #     enc_layers: 4
  #     n_head: 4
  #     n_embd: 40
  #     kernel_temp: 8
  #     pool: 5
  #     pool_hop: 2
  #     block_size: 50 # 2s
  #     dropout: 0.4
  #     classifier: True
  #     bias: True

  # - model: 'Conformer' # modelo pequeño embed pequeño
  #   train_params:
  #     batch_size: 128              
  #     max_epoch: 200              
  #     lr: 1e-06
  #     weight_decay: 1e-04                     
  #     early_stopping_patience: 5
  #     scheduler_patience: 2
  #   dataset_params:
  #     window_len: 50  
  #     hop: 1          
  #     filt: False       
  #     fixed: False      
  #     rnd_trials: False   
  #     unit_output: True
  #   model_params:
  #     mlp_ratio: 2
  #     enc_layers: 2
  #     n_head: 2
  #     n_embd: 10
  #     kernel_temp: 8
  #     pool: 10
  #     pool_hop: 2
  #     block_size: 50 # 2s
  #     dropout: 0.4
  #     classifier: True
  #     bias: True

  # - model: 'Conformer' # modelo normal embed pequeño
  #   train_params:
  #     batch_size: 128              
  #     max_epoch: 200              
  #     lr: 1e-06
  #     weight_decay: 1e-04                     
  #     early_stopping_patience: 5
  #     scheduler_patience: 2
  #   dataset_params:
  #     window_len: 50  
  #     hop: 1          
  #     filt: False       
  #     fixed: False      
  #     rnd_trials: False   
  #     unit_output: True
  #   model_params:
  #     mlp_ratio: 2
  #     enc_layers: 4
  #     n_head: 2
  #     n_embd: 10
  #     kernel_temp: 8
  #     pool: 5
  #     pool_hop: 2
  #     block_size: 50 # 2s
  #     dropout: 0.4
  #     classifier: True
  #     bias: True

  # - model: 'Conformer' # embed grande modelo grande
  #   train_params:
  #     batch_size: 128              
  #     max_epoch: 200              
  #     lr: 1e-06
  #     weight_decay: 1e-04                     
  #     early_stopping_patience: 5
  #     scheduler_patience: 2
  #   dataset_params:
  #     window_len: 50  
  #     hop: 1          
  #     filt: False       
  #     fixed: False      
  #     rnd_trials: False   
  #     unit_output: True
  #   model_params:
  #     mlp_ratio: 2
  #     enc_layers: 8
  #     n_head: 4
  #     n_embd: 80
  #     kernel_temp: 8
  #     pool: 5
  #     pool_hop: 2
  #     block_size: 50 # 2s
  #     dropout: 0.4
  #     classifier: True
  #     bias: True

  # - model: 'Conformer' # embed grande modelo normal
  #   train_params:
  #     batch_size: 128              
  #     max_epoch: 200              
  #     lr: 1e-06
  #     weight_decay: 1e-04                     
  #     early_stopping_patience: 5
  #     scheduler_patience: 2
  #   dataset_params:
  #     window_len: 50  
  #     hop: 1          
  #     filt: False       
  #     fixed: False      
  #     rnd_trials: False   
  #     unit_output: True
  #   model_params:
  #     mlp_ratio: 2
  #     enc_layers: 8
  #     n_head: 4
  #     n_embd: 80
  #     kernel_temp: 8
  #     pool: 5
  #     pool_hop: 2
  #     block_size: 50 # 2s
  #     dropout: 0.4
  #     classifier: True
  #     bias: True

  - model: 'Conformer' # embed 20 modelo pequeño
    train_params:
      batch_size: 128              
      max_epoch: 200              
      lr: 1e-06
      weight_decay: 1e-04                     
      early_stopping_patience: 5
      scheduler_patience: 2
    dataset_params:
      window_len: 50  
      hop: 1          
      filt: False       
      fixed: False      
      rnd_trials: False   
      unit_output: True
    model_params:
      mlp_ratio: 2
      enc_layers: 2
      n_head: 2
      n_embd: 20
      kernel_temp: 8
      pool: 10
      pool_hop: 4
      block_size: 50 # 2s
      dropout: 0.4
      classifier: True
      bias: True

  - model: 'Conformer' # embed 10 modelo muy pequeño
    train_params:
      batch_size: 128              
      max_epoch: 200              
      lr: 1e-06
      weight_decay: 1e-04                     
      early_stopping_patience: 5
      scheduler_patience: 2
    dataset_params:
      window_len: 50  
      hop: 1          
      filt: False       
      fixed: False      
      rnd_trials: False   
      unit_output: True
    model_params:
      mlp_ratio: 2
      enc_layers: 2
      n_head: 2
      n_embd: 10
      kernel_temp: 8
      pool: 20
      pool_hop: 5
      block_size: 50 # 2s
      dropout: 0.4
      classifier: True
      bias: True