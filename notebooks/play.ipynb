{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Include parent dir\n",
    "SCRIPT_DIR = os.path.dirname(os.path.abspath('play.ipynb'))\n",
    "sys.path.append(os.path.dirname(SCRIPT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = [55, 60, 50, 45]\n",
    "np.mean(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRADIENT CONFORMER COMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.eeg_conformer import Conformer, ConformerConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 0.41M\n"
     ]
    }
   ],
   "source": [
    "mdl = Conformer(ConformerConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jaulab\\Desktop\\deepAAD_project\\models\\eeg_conformer.py:271: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(module.weight, mode= 'fan_out', nonlinearity='relu')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Conformer(\n",
       "  (embed): PatchEmbedding(\n",
       "    (shallownet): ModuleList(\n",
       "      (0): Conv2d(1, 40, kernel_size=(1, 8), stride=(1, 1))\n",
       "      (1): Conv2d(40, 40, kernel_size=(64, 1), stride=(1, 1))\n",
       "      (2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ELU(alpha=1.0)\n",
       "      (4): AvgPool2d(kernel_size=(1, 20), stride=(1, 4), padding=0)\n",
       "      (5): Dropout(p=0.4, inplace=False)\n",
       "    )\n",
       "    (projection): Conv2d(40, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (0): EncoderBlock(\n",
       "      (ln_1): LayerNorm()\n",
       "      (attn): TemporalSelfAttention(\n",
       "        (w_q): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (w_k): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (w_v): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (c_proj): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.4, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm()\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(in_features=40, out_features=80, bias=True)\n",
       "        (gelu): GELU(approximate='none')\n",
       "        (c_proj): Linear(in_features=80, out_features=40, bias=True)\n",
       "        (dropout): Dropout(p=0.4, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): EncoderBlock(\n",
       "      (ln_1): LayerNorm()\n",
       "      (attn): TemporalSelfAttention(\n",
       "        (w_q): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (w_k): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (w_v): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (c_proj): Linear(in_features=40, out_features=40, bias=True)\n",
       "        (attn_dropout): Dropout(p=0.4, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.4, inplace=False)\n",
       "      )\n",
       "      (ln_2): LayerNorm()\n",
       "      (mlp): MLP(\n",
       "        (c_fc): Linear(in_features=40, out_features=80, bias=True)\n",
       "        (gelu): GELU(approximate='none')\n",
       "        (c_proj): Linear(in_features=80, out_features=40, bias=True)\n",
       "        (dropout): Dropout(p=0.4, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classif): ClassificationHead(\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=1040, out_features=256, bias=True)\n",
       "      (1): ELU(alpha=1.0)\n",
       "      (2): Dropout(p=0.4, inplace=False)\n",
       "      (3): Linear(in_features=256, out_features=32, bias=True)\n",
       "      (4): ELU(alpha=1.0)\n",
       "      (5): Dropout(p=0.4, inplace=False)\n",
       "      (6): Linear(in_features=32, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl.apply(mdl.init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64]), tensor(0.0422, grad_fn=<NegBackward0>))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((64, 64, 128))\n",
    "target = torch.randn(64)\n",
    "logits, loss = mdl(x, target)\n",
    "logits.shape, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer embed.shallownet.0.weight: tensor([[[[-1.1589e-01, -1.5722e-01, -1.4105e-01, -1.7125e-01, -1.8921e-01,\n",
      "           -1.4967e-01, -2.0296e-01, -2.3040e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.7813e-02, -7.5573e-02, -8.4988e-02, -4.3029e-02, -2.5184e-02,\n",
      "           -1.1964e-02, -5.2214e-02, -4.5621e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7741e-02,  1.9373e-02,  4.6946e-02,  5.7790e-02,  7.1441e-02,\n",
      "            1.4077e-01,  9.1989e-02,  1.0884e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.3034e-02,  7.0245e-02, -3.6819e-05,  4.3412e-03,  9.4979e-02,\n",
      "            1.1864e-01,  6.5652e-02,  1.2992e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6778e-01, -1.4607e-01, -1.6653e-01, -3.4871e-02,  3.6625e-02,\n",
      "            7.3078e-02,  7.1132e-02,  4.2567e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.3703e-02, -1.1809e-01, -3.7278e-02, -1.0814e-01, -3.8427e-02,\n",
      "           -7.2157e-02, -4.8850e-02, -8.6604e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5178e-02,  3.9372e-02, -3.1354e-02, -1.9728e-02,  9.2279e-02,\n",
      "           -3.2841e-03,  3.6951e-02, -5.6273e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.9252e-02, -4.3034e-02, -2.0035e-02, -6.9322e-02, -9.5295e-02,\n",
      "           -1.2472e-01, -4.0214e-02, -5.9196e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6755e-01,  8.4133e-02,  2.5927e-01,  1.9620e-01,  1.9895e-01,\n",
      "            2.3558e-01,  2.1242e-01,  1.7021e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2956e-02, -7.1677e-02, -1.5721e-01, -8.8095e-02, -1.0712e-01,\n",
      "           -5.6246e-02, -4.1395e-02, -8.2441e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.2189e-02, -3.8768e-02,  6.3165e-02, -2.7310e-02,  5.8715e-02,\n",
      "           -9.2154e-02, -1.0475e-01, -1.6921e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.4420e-02, -9.0502e-02, -1.1436e-01, -2.1346e-01, -8.5457e-02,\n",
      "           -8.1157e-02, -9.9662e-02, -1.1931e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.1362e-02, -6.1797e-02,  3.3049e-02, -1.3570e-01,  4.6090e-02,\n",
      "           -1.7322e-02, -3.4026e-02, -2.5445e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0872e-02, -1.7325e-02,  7.5546e-04,  2.6919e-02, -7.7964e-02,\n",
      "           -8.3474e-02, -5.4329e-02, -7.3043e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.8020e-02,  1.2241e-01, -1.0308e-02,  3.5199e-02, -1.8756e-02,\n",
      "            3.7002e-02,  4.6110e-02,  3.3178e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4632e-01, -1.1443e-01, -1.4998e-01, -1.8892e-01, -1.9809e-01,\n",
      "           -1.8025e-01, -1.5690e-01, -1.3022e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3815e-02, -3.1636e-03,  5.3839e-02,  5.3837e-02,  2.7505e-02,\n",
      "           -2.2611e-02,  5.9873e-02,  1.6542e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2329e-01, -1.3719e-01, -1.6895e-01, -1.2609e-01, -1.5468e-01,\n",
      "           -1.8410e-01, -1.8472e-01, -8.3709e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.1959e-03,  1.8171e-03,  9.6531e-03, -5.7373e-02, -3.4826e-02,\n",
      "            3.0582e-02, -3.9571e-03, -6.8340e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5424e-01, -1.1209e-01, -6.4608e-02, -5.7586e-02, -1.1630e-01,\n",
      "           -2.7283e-02, -2.8581e-02, -7.2551e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.9518e-02, -2.0217e-02, -8.6425e-02, -1.1065e-01, -1.8286e-01,\n",
      "           -2.1284e-01, -2.9614e-01, -1.7206e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5870e-01, -1.6259e-01, -1.7981e-01, -1.3538e-01, -7.8624e-02,\n",
      "           -2.4319e-01, -1.5520e-01, -2.0723e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.5352e-02, -5.4902e-02,  3.9277e-02, -3.0825e-03, -1.9903e-02,\n",
      "            1.8694e-02,  8.5011e-02,  9.1127e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6606e-01,  2.0479e-01,  2.3289e-01,  2.2394e-01,  1.8106e-01,\n",
      "            2.7050e-01,  2.5175e-01,  2.5302e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.7014e-02, -6.4426e-02,  3.3906e-02, -2.2986e-03, -1.2864e-01,\n",
      "           -8.3621e-02, -3.7100e-02, -7.1138e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4543e-01,  1.4879e-03, -9.0206e-02, -3.3114e-02,  1.1337e-01,\n",
      "           -1.5864e-03, -9.0448e-02, -1.0051e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.3414e-02, -9.7839e-02, -1.5067e-01, -4.1812e-02, -8.6255e-02,\n",
      "           -6.7230e-04, -1.0719e-01, -5.7549e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.1126e-02,  7.6078e-02, -3.8998e-02, -6.9709e-02,  5.7189e-02,\n",
      "           -4.3880e-02,  4.1222e-02,  3.9783e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.7476e-02, -8.3580e-02, -9.9724e-02, -1.0694e-01, -8.7092e-02,\n",
      "           -1.3861e-01, -9.9671e-02, -1.6146e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.4274e-02,  1.6712e-02, -4.9909e-02,  6.3868e-03, -4.0634e-02,\n",
      "            5.5682e-02, -1.2319e-01, -9.7783e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2050e-02, -3.2767e-02,  7.8985e-02, -3.4118e-02,  8.7904e-02,\n",
      "            5.5776e-02,  6.0527e-02, -2.6301e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0160e-02,  1.1743e-01,  8.3986e-02,  2.5767e-02,  9.7119e-02,\n",
      "            1.1971e-01,  9.1688e-02,  6.2665e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2054e-01,  4.9434e-03, -2.6894e-02,  1.9171e-02, -2.6772e-03,\n",
      "           -3.2047e-02, -4.7399e-02, -2.5902e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2041e-01,  2.2563e-02, -8.1646e-03,  7.1449e-03, -2.9212e-02,\n",
      "            1.5438e-02,  9.0308e-02,  1.4400e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2966e-01, -1.4286e-01, -1.6104e-01, -7.6102e-02, -8.5609e-02,\n",
      "           -1.9393e-02, -1.0236e-02, -7.1848e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8903e-03,  3.2018e-02,  6.6274e-02,  2.9857e-02,  4.0263e-02,\n",
      "            3.0140e-02,  4.3994e-02,  1.0951e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4716e-02,  6.2690e-02,  9.1292e-02, -4.8256e-03,  7.1401e-02,\n",
      "            3.3814e-02, -6.6018e-02, -9.2605e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2186e-02,  3.6181e-02,  8.4914e-03, -5.9387e-04,  1.2603e-01,\n",
      "           -1.8195e-02,  5.9142e-02,  4.7500e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1585e-01, -2.0815e-01, -1.5258e-01, -7.5857e-02, -9.8278e-02,\n",
      "           -6.0451e-02, -8.2885e-02, -1.8183e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9128e-02, -5.7358e-02, -1.6561e-01, -9.9239e-02, -9.7688e-02,\n",
      "           -1.9486e-02,  2.1053e-02,  2.6148e-02]]]])\n",
      "Layer embed.shallownet.0.bias: tensor([-1.5646e-06, -3.8743e-07,  8.6427e-07,  2.7493e-06, -3.0547e-06,\n",
      "        -2.5034e-06, -2.6524e-06, -4.3213e-07,  2.9504e-06, -1.5497e-06,\n",
      "        -3.9041e-06, -3.4422e-06, -7.1526e-07,  8.9407e-07,  6.6310e-07,\n",
      "        -6.7055e-07, -7.8976e-07,  2.3693e-06, -1.9372e-07, -2.1458e-06,\n",
      "        -3.6061e-06, -1.9372e-07, -1.6838e-06,  3.5763e-07, -1.9670e-06,\n",
      "        -2.6524e-06, -3.7253e-07,  1.5795e-06,  1.7881e-07, -5.8115e-07,\n",
      "        -7.8231e-07,  2.5313e-06, -1.3411e-06, -3.8743e-07,  4.4703e-07,\n",
      "        -2.0303e-07,  8.7917e-07, -1.0915e-06, -2.9206e-06,  4.2096e-06])\n",
      "Layer embed.shallownet.1.weight: tensor([[[[ 3.2770e-04],\n",
      "          [-8.4251e-03],\n",
      "          [ 1.0284e-02],\n",
      "          ...,\n",
      "          [ 1.3858e-02],\n",
      "          [-1.8389e-03],\n",
      "          [ 1.0252e-02]],\n",
      "\n",
      "         [[ 9.0790e-03],\n",
      "          [ 2.9196e-02],\n",
      "          [ 1.3023e-02],\n",
      "          ...,\n",
      "          [ 2.4092e-02],\n",
      "          [ 3.9982e-02],\n",
      "          [-1.6530e-02]],\n",
      "\n",
      "         [[ 4.1796e-03],\n",
      "          [-4.2203e-03],\n",
      "          [ 6.1171e-03],\n",
      "          ...,\n",
      "          [ 5.2686e-03],\n",
      "          [-4.0109e-03],\n",
      "          [ 3.9926e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2726e-02],\n",
      "          [-8.1663e-03],\n",
      "          [ 5.6817e-03],\n",
      "          ...,\n",
      "          [-4.3343e-03],\n",
      "          [-2.7638e-03],\n",
      "          [ 1.3486e-02]],\n",
      "\n",
      "         [[-3.4679e-03],\n",
      "          [-1.4732e-02],\n",
      "          [ 8.8682e-03],\n",
      "          ...,\n",
      "          [-4.6994e-03],\n",
      "          [-1.4202e-02],\n",
      "          [ 6.1454e-03]],\n",
      "\n",
      "         [[ 1.3272e-02],\n",
      "          [-9.6069e-03],\n",
      "          [ 6.7541e-03],\n",
      "          ...,\n",
      "          [-5.4358e-04],\n",
      "          [ 4.9557e-03],\n",
      "          [-7.2347e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2634e-02],\n",
      "          [ 7.2953e-03],\n",
      "          [-9.3210e-03],\n",
      "          ...,\n",
      "          [ 2.6452e-02],\n",
      "          [ 2.4856e-02],\n",
      "          [ 8.2439e-03]],\n",
      "\n",
      "         [[-3.2753e-02],\n",
      "          [ 1.3611e-02],\n",
      "          [ 6.7687e-02],\n",
      "          ...,\n",
      "          [ 1.9507e-03],\n",
      "          [-5.1355e-02],\n",
      "          [-1.9031e-02]],\n",
      "\n",
      "         [[ 8.5199e-03],\n",
      "          [-6.4834e-04],\n",
      "          [-9.8020e-03],\n",
      "          ...,\n",
      "          [ 2.4733e-03],\n",
      "          [ 9.2818e-03],\n",
      "          [-8.2097e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0122e-02],\n",
      "          [-9.6787e-04],\n",
      "          [-2.0455e-02],\n",
      "          ...,\n",
      "          [ 1.2709e-02],\n",
      "          [ 3.0875e-02],\n",
      "          [ 8.7396e-03]],\n",
      "\n",
      "         [[ 1.7871e-02],\n",
      "          [-1.0089e-02],\n",
      "          [-3.2826e-02],\n",
      "          ...,\n",
      "          [ 9.6429e-03],\n",
      "          [ 2.2312e-02],\n",
      "          [ 1.3036e-02]],\n",
      "\n",
      "         [[-2.8582e-03],\n",
      "          [ 1.0494e-02],\n",
      "          [-1.1718e-03],\n",
      "          ...,\n",
      "          [ 2.8157e-03],\n",
      "          [ 6.9683e-03],\n",
      "          [ 3.6559e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.0568e-02],\n",
      "          [-1.3581e-02],\n",
      "          [ 7.2287e-04],\n",
      "          ...,\n",
      "          [ 6.5996e-04],\n",
      "          [ 6.3385e-03],\n",
      "          [ 1.3008e-02]],\n",
      "\n",
      "         [[ 1.8651e-02],\n",
      "          [-2.2825e-02],\n",
      "          [-1.0015e-02],\n",
      "          ...,\n",
      "          [ 5.1593e-02],\n",
      "          [-2.3440e-02],\n",
      "          [ 3.2730e-02]],\n",
      "\n",
      "         [[-9.7497e-03],\n",
      "          [-1.2746e-03],\n",
      "          [-2.1619e-03],\n",
      "          ...,\n",
      "          [-1.1488e-02],\n",
      "          [ 1.8769e-03],\n",
      "          [-1.3804e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2537e-02],\n",
      "          [-9.8670e-04],\n",
      "          [ 8.3699e-03],\n",
      "          ...,\n",
      "          [-1.1954e-02],\n",
      "          [ 1.2705e-02],\n",
      "          [-9.3738e-03]],\n",
      "\n",
      "         [[-1.5553e-02],\n",
      "          [ 8.9627e-04],\n",
      "          [ 6.5606e-03],\n",
      "          ...,\n",
      "          [-2.6115e-02],\n",
      "          [ 9.3453e-03],\n",
      "          [-4.7663e-03]],\n",
      "\n",
      "         [[-3.7335e-03],\n",
      "          [ 6.3487e-03],\n",
      "          [ 4.8443e-03],\n",
      "          ...,\n",
      "          [-4.2321e-03],\n",
      "          [ 1.1359e-02],\n",
      "          [-3.3889e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.1283e-03],\n",
      "          [ 3.3845e-02],\n",
      "          [ 9.8697e-03],\n",
      "          ...,\n",
      "          [ 3.9171e-03],\n",
      "          [ 3.0717e-03],\n",
      "          [ 1.1255e-03]],\n",
      "\n",
      "         [[ 5.8927e-03],\n",
      "          [ 2.0072e-02],\n",
      "          [ 9.4331e-03],\n",
      "          ...,\n",
      "          [ 3.9140e-03],\n",
      "          [ 9.9385e-03],\n",
      "          [-1.8345e-03]],\n",
      "\n",
      "         [[-7.3490e-04],\n",
      "          [ 9.0839e-04],\n",
      "          [-6.5052e-03],\n",
      "          ...,\n",
      "          [ 3.1725e-03],\n",
      "          [ 9.6356e-04],\n",
      "          [ 7.0762e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9837e-03],\n",
      "          [-3.1682e-03],\n",
      "          [-1.3170e-02],\n",
      "          ...,\n",
      "          [-8.1022e-04],\n",
      "          [ 4.0639e-03],\n",
      "          [ 8.3921e-03]],\n",
      "\n",
      "         [[-8.2214e-03],\n",
      "          [-8.2805e-05],\n",
      "          [ 4.1046e-03],\n",
      "          ...,\n",
      "          [ 1.9644e-05],\n",
      "          [-2.6612e-03],\n",
      "          [ 8.8424e-03]],\n",
      "\n",
      "         [[ 1.2286e-02],\n",
      "          [-2.1196e-02],\n",
      "          [-1.5203e-02],\n",
      "          ...,\n",
      "          [-2.2400e-05],\n",
      "          [ 3.1555e-03],\n",
      "          [-5.5806e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3965e-03],\n",
      "          [ 1.7166e-02],\n",
      "          [ 8.8181e-03],\n",
      "          ...,\n",
      "          [ 4.1143e-03],\n",
      "          [ 1.1750e-02],\n",
      "          [-8.5231e-03]],\n",
      "\n",
      "         [[-1.1879e-02],\n",
      "          [-4.9034e-03],\n",
      "          [ 1.7644e-02],\n",
      "          ...,\n",
      "          [-3.5251e-05],\n",
      "          [ 1.2670e-02],\n",
      "          [ 1.0619e-02]],\n",
      "\n",
      "         [[-3.1212e-03],\n",
      "          [ 6.2348e-03],\n",
      "          [-2.0308e-03],\n",
      "          ...,\n",
      "          [ 5.1686e-03],\n",
      "          [-1.1381e-03],\n",
      "          [-2.1465e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1823e-02],\n",
      "          [ 1.3413e-02],\n",
      "          [-1.9217e-02],\n",
      "          ...,\n",
      "          [-6.1350e-03],\n",
      "          [-7.1531e-03],\n",
      "          [-2.5732e-03]],\n",
      "\n",
      "         [[ 5.7832e-04],\n",
      "          [ 9.1023e-03],\n",
      "          [-1.3833e-02],\n",
      "          ...,\n",
      "          [ 1.1989e-02],\n",
      "          [-5.8008e-03],\n",
      "          [-1.3486e-02]],\n",
      "\n",
      "         [[-1.9568e-02],\n",
      "          [ 4.6989e-03],\n",
      "          [-7.9666e-04],\n",
      "          ...,\n",
      "          [ 9.9482e-04],\n",
      "          [ 7.1221e-03],\n",
      "          [ 1.1180e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4547e-02],\n",
      "          [-2.9288e-03],\n",
      "          [-1.8932e-02],\n",
      "          ...,\n",
      "          [ 3.6320e-03],\n",
      "          [-1.0416e-02],\n",
      "          [ 7.1267e-04]],\n",
      "\n",
      "         [[ 6.5576e-03],\n",
      "          [-4.6310e-02],\n",
      "          [-1.3666e-02],\n",
      "          ...,\n",
      "          [-3.4317e-02],\n",
      "          [ 2.6995e-02],\n",
      "          [-2.3344e-02]],\n",
      "\n",
      "         [[-4.7897e-03],\n",
      "          [ 7.5651e-03],\n",
      "          [ 1.1793e-03],\n",
      "          ...,\n",
      "          [ 1.7518e-03],\n",
      "          [-5.5478e-03],\n",
      "          [-1.7726e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5787e-02],\n",
      "          [ 2.1232e-02],\n",
      "          [ 6.9839e-03],\n",
      "          ...,\n",
      "          [ 4.8301e-03],\n",
      "          [-6.1823e-03],\n",
      "          [ 1.1012e-02]],\n",
      "\n",
      "         [[-8.3081e-03],\n",
      "          [ 1.8619e-02],\n",
      "          [ 5.0475e-03],\n",
      "          ...,\n",
      "          [ 1.5349e-02],\n",
      "          [-2.2394e-02],\n",
      "          [ 1.7154e-02]],\n",
      "\n",
      "         [[-2.3535e-03],\n",
      "          [ 9.1042e-04],\n",
      "          [ 3.8492e-03],\n",
      "          ...,\n",
      "          [-9.2525e-03],\n",
      "          [ 2.3384e-02],\n",
      "          [-4.5037e-03]]]])\n",
      "Layer embed.shallownet.1.bias: tensor([-1.2200e-07,  1.4901e-08,  2.5332e-07, -1.4901e-08,  2.7567e-07,\n",
      "        -4.5449e-07, -2.1607e-07, -1.1176e-08, -2.9802e-08, -1.4901e-07,\n",
      "         3.7253e-09,  1.1921e-07, -2.8312e-07,  1.4901e-07, -1.5646e-07,\n",
      "         3.0175e-07,  4.4703e-08,  2.4948e-07, -1.0431e-07, -1.4901e-08,\n",
      "        -7.4506e-09, -1.7881e-07, -2.8312e-07, -1.0803e-07,  2.7567e-07,\n",
      "        -4.7684e-07, -1.1548e-07,  2.9802e-08,  4.1723e-07,  8.1956e-08,\n",
      "        -2.9802e-08, -1.4901e-07, -1.0431e-07, -2.2352e-07, -3.2037e-07,\n",
      "        -2.7567e-07, -1.0815e-07,  8.1956e-08, -2.2352e-07, -2.5332e-07])\n",
      "Layer embed.shallownet.2.weight: tensor([ 0.0277,  0.0609, -0.0324,  0.0588, -0.0259, -0.0158,  0.0096,  0.0007,\n",
      "         0.0402, -0.0059, -0.0253,  0.0451, -0.0030, -0.0104,  0.0154, -0.0445,\n",
      "         0.0108, -0.0272, -0.0053,  0.0618, -0.0192,  0.0712, -0.0027, -0.0385,\n",
      "        -0.0245, -0.0079, -0.0456, -0.0006, -0.0602, -0.0435, -0.0387, -0.0260,\n",
      "        -0.0034, -0.0271,  0.0343, -0.0114,  0.0768,  0.0158, -0.0005,  0.0266])\n",
      "Layer embed.shallownet.2.bias: tensor([ 0.0430,  0.1971, -0.0979,  0.1361, -0.0589, -0.0327, -0.0130, -0.0602,\n",
      "         0.0416, -0.0536, -0.0147,  0.1116,  0.0672, -0.0902, -0.0151, -0.1391,\n",
      "        -0.0147, -0.0893,  0.0234,  0.1826, -0.0932,  0.1069,  0.0032, -0.0915,\n",
      "        -0.0600,  0.0255, -0.0977,  0.0466, -0.1377, -0.1004, -0.0135, -0.0828,\n",
      "         0.0038, -0.1050,  0.0801,  0.0403,  0.1781,  0.0356,  0.0323,  0.0871])\n",
      "Layer embed.projection.weight: tensor([[[[-6.8488e-03]],\n",
      "\n",
      "         [[-1.4494e-04]],\n",
      "\n",
      "         [[-1.2159e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1764e-02]],\n",
      "\n",
      "         [[ 1.0430e-02]],\n",
      "\n",
      "         [[-2.3510e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.5636e-04]],\n",
      "\n",
      "         [[ 6.7975e-03]],\n",
      "\n",
      "         [[ 2.1861e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.6233e-02]],\n",
      "\n",
      "         [[-1.0818e-03]],\n",
      "\n",
      "         [[ 1.4587e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7097e-02]],\n",
      "\n",
      "         [[ 3.6683e-03]],\n",
      "\n",
      "         [[ 3.4209e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.7185e-02]],\n",
      "\n",
      "         [[ 1.9372e-02]],\n",
      "\n",
      "         [[-1.5462e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.4940e-02]],\n",
      "\n",
      "         [[-2.9256e-02]],\n",
      "\n",
      "         [[-2.0690e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.2906e-05]],\n",
      "\n",
      "         [[-7.1400e-05]],\n",
      "\n",
      "         [[-1.2569e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5806e-02]],\n",
      "\n",
      "         [[ 2.1479e-02]],\n",
      "\n",
      "         [[ 1.8702e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3965e-02]],\n",
      "\n",
      "         [[ 1.7058e-02]],\n",
      "\n",
      "         [[ 1.7775e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6600e-03]],\n",
      "\n",
      "         [[-8.5604e-03]],\n",
      "\n",
      "         [[-3.8550e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.1095e-02]],\n",
      "\n",
      "         [[-1.0297e-02]],\n",
      "\n",
      "         [[ 1.7597e-02]]]])\n",
      "Layer embed.projection.bias: tensor([-0.0478,  0.0476,  0.0168,  0.0341, -0.1237,  0.0045, -0.0526,  0.1340,\n",
      "        -0.0156,  0.0567, -0.1011,  0.0527,  0.0389, -0.0226,  0.0645, -0.0670,\n",
      "        -0.0168, -0.0360,  0.0219,  0.0117, -0.0620, -0.0051,  0.0421,  0.0386,\n",
      "         0.0549, -0.0813, -0.0146,  0.0549, -0.0568,  0.0092, -0.0130, -0.0017,\n",
      "         0.0846, -0.0408,  0.0747, -0.1115,  0.0265, -0.0380,  0.0943, -0.0552])\n",
      "Layer encoder.0.ln_1.weight: tensor([-0.0077,  0.0579,  0.0317,  0.0245,  0.0222,  0.0198, -0.0093, -0.0247,\n",
      "         0.0022,  0.0070, -0.0261,  0.0616, -0.0059,  0.0314,  0.0102, -0.0201,\n",
      "         0.0076, -0.0343, -0.0238, -0.0389,  0.0087,  0.0387, -0.0299,  0.0268,\n",
      "         0.0114,  0.0216,  0.0190,  0.0064,  0.0286, -0.0190,  0.0310, -0.0231,\n",
      "         0.0068, -0.0220, -0.0071, -0.0619,  0.0274,  0.0485, -0.0101, -0.0026])\n",
      "Layer encoder.0.ln_1.bias: tensor([-0.0323, -0.0042, -0.0935,  0.0703,  0.0345,  0.0136, -0.0130,  0.0244,\n",
      "         0.0496, -0.0152,  0.0849, -0.0220,  0.0535, -0.0056,  0.0010,  0.0290,\n",
      "        -0.0226, -0.0163, -0.0096, -0.0126,  0.0218, -0.0291,  0.0126, -0.0142,\n",
      "        -0.0369, -0.0680, -0.0187,  0.0511,  0.0274,  0.0574, -0.0049, -0.0736,\n",
      "         0.0158,  0.0776, -0.0223,  0.0416,  0.0666,  0.0428, -0.0159, -0.0232])\n",
      "Layer encoder.0.attn.w_q.weight: tensor([[ 0.0007, -0.0065,  0.0032,  ...,  0.0085,  0.0038,  0.0108],\n",
      "        [ 0.0024,  0.0070, -0.0059,  ..., -0.0082, -0.0089, -0.0263],\n",
      "        [ 0.0001, -0.0087,  0.0027,  ..., -0.0051, -0.0077,  0.0076],\n",
      "        ...,\n",
      "        [ 0.0100, -0.0017,  0.0144,  ..., -0.0040, -0.0022, -0.0050],\n",
      "        [ 0.0082, -0.0029,  0.0050,  ..., -0.0006, -0.0082, -0.0053],\n",
      "        [-0.0153, -0.0080, -0.0021,  ...,  0.0116,  0.0160,  0.0142]])\n",
      "Layer encoder.0.attn.w_q.bias: tensor([ 1.0819e-02,  9.5664e-05,  9.8624e-03,  7.2805e-03, -1.8245e-02,\n",
      "        -2.1732e-03,  1.2976e-02, -1.1960e-02, -4.4977e-04, -8.5797e-03,\n",
      "         1.8121e-02,  1.4010e-03,  7.9997e-03,  1.4132e-02,  1.9846e-03,\n",
      "         6.4686e-03, -6.0761e-04, -3.3781e-02,  7.6416e-03, -8.7142e-04,\n",
      "        -1.2602e-03,  8.2443e-04, -1.2862e-02,  4.0294e-03,  1.8948e-02,\n",
      "        -1.1158e-02,  2.6228e-03,  7.9039e-03, -1.1538e-02,  9.0288e-03,\n",
      "         8.2613e-03,  2.8628e-04, -1.7248e-04,  8.8429e-03, -1.5726e-02,\n",
      "        -5.9742e-03,  1.0463e-02,  8.2370e-03, -1.3785e-02, -2.5319e-03])\n",
      "Layer encoder.0.attn.w_k.weight: tensor([[ 0.0095, -0.0027, -0.0029,  ..., -0.0076,  0.0167,  0.0108],\n",
      "        [-0.0019,  0.0150,  0.0014,  ..., -0.0031,  0.0011, -0.0104],\n",
      "        [-0.0101, -0.0131,  0.0011,  ...,  0.0067, -0.0052, -0.0068],\n",
      "        ...,\n",
      "        [-0.0011,  0.0044,  0.0046,  ...,  0.0065, -0.0028, -0.0101],\n",
      "        [-0.0115, -0.0254,  0.0027,  ...,  0.0024,  0.0168,  0.0029],\n",
      "        [-0.0005,  0.0049,  0.0150,  ..., -0.0131, -0.0044,  0.0030]])\n",
      "Layer encoder.0.attn.w_k.bias: tensor([-1.1823e-10,  4.7658e-10,  9.5861e-10,  1.8208e-09, -2.7067e-09,\n",
      "        -4.3838e-10,  1.5825e-10, -1.5025e-09,  2.5921e-09, -1.1569e-09,\n",
      "         3.3469e-10,  8.0036e-10,  1.3897e-09,  1.5780e-09,  6.4028e-10,\n",
      "         3.2960e-09, -3.0777e-09, -4.7476e-10, -4.2201e-10, -8.1491e-10,\n",
      "        -1.1169e-09, -1.3570e-09, -1.7462e-10,  2.0736e-09,  1.4679e-09,\n",
      "         6.1846e-10,  3.1259e-09, -4.1837e-10,  3.8381e-10,  1.5225e-09,\n",
      "         8.0763e-10, -1.8990e-09,  9.3132e-10, -9.3132e-10,  9.3132e-10,\n",
      "        -2.7940e-09,  4.6566e-10, -6.9849e-10,  4.6566e-10, -4.6566e-10])\n",
      "Layer encoder.0.attn.w_v.weight: tensor([[ 0.0052,  0.0163,  0.0185,  ...,  0.0004,  0.0114, -0.0094],\n",
      "        [-0.0004,  0.0010,  0.0051,  ...,  0.0015,  0.0101,  0.0012],\n",
      "        [-0.0008,  0.0037, -0.0012,  ...,  0.0050,  0.0137, -0.0049],\n",
      "        ...,\n",
      "        [-0.0031, -0.0046,  0.0092,  ..., -0.0031, -0.0114,  0.0061],\n",
      "        [ 0.0057, -0.0048, -0.0090,  ...,  0.0091,  0.0038, -0.0029],\n",
      "        [ 0.0140,  0.0149,  0.0006,  ...,  0.0045, -0.0054, -0.0070]])\n",
      "Layer encoder.0.attn.w_v.bias: tensor([-0.0058, -0.0425,  0.0249, -0.0034, -0.0173, -0.0446, -0.0403,  0.0043,\n",
      "         0.0093, -0.0289, -0.0533,  0.0191, -0.0006,  0.0109,  0.0262, -0.0265,\n",
      "         0.0003,  0.0612,  0.0367,  0.0212, -0.0155,  0.0144, -0.0465, -0.0421,\n",
      "         0.0314,  0.0371, -0.0324, -0.0176, -0.0118, -0.0041,  0.0327, -0.0247,\n",
      "        -0.0504, -0.0036,  0.0381,  0.0143,  0.0382, -0.0135,  0.0239, -0.0051])\n",
      "Layer encoder.0.attn.c_proj.weight: tensor([[ 0.0084,  0.0077, -0.0013,  ...,  0.0121,  0.0050, -0.0088],\n",
      "        [-0.0090,  0.0066, -0.0005,  ..., -0.0136, -0.0025, -0.0081],\n",
      "        [ 0.0311,  0.0139,  0.0026,  ..., -0.0023, -0.0124, -0.0015],\n",
      "        ...,\n",
      "        [ 0.0164,  0.0042,  0.0208,  ..., -0.0101,  0.0032,  0.0167],\n",
      "        [ 0.0120,  0.0123, -0.0062,  ..., -0.0130,  0.0021,  0.0163],\n",
      "        [-0.0180, -0.0146,  0.0009,  ...,  0.0184, -0.0061, -0.0054]])\n",
      "Layer encoder.0.attn.c_proj.bias: tensor([-0.0432, -0.0167, -0.0718,  0.0157,  0.0023,  0.0440,  0.0205,  0.0225,\n",
      "         0.0444, -0.0144,  0.0430, -0.0171,  0.0395,  0.0071,  0.0065,  0.0080,\n",
      "         0.0111,  0.0248,  0.0389, -0.0295, -0.0157, -0.0823,  0.0077, -0.0179,\n",
      "        -0.0372,  0.0299, -0.0032,  0.0212,  0.0361, -0.0266, -0.0283, -0.0552,\n",
      "        -0.0018, -0.0515,  0.0097,  0.0473,  0.0251,  0.0743, -0.0219, -0.0241])\n",
      "Layer encoder.0.ln_2.weight: tensor([-0.0187, -0.0115, -0.0210, -0.0102,  0.0079,  0.0222,  0.0313,  0.0164,\n",
      "        -0.0079,  0.0098, -0.0173,  0.0310, -0.0309,  0.0006,  0.0010, -0.0189,\n",
      "         0.0109, -0.0005, -0.0021, -0.0033, -0.0090,  0.0101,  0.0010,  0.0193,\n",
      "         0.0205,  0.0118,  0.0015, -0.0082,  0.0268,  0.0002,  0.0175, -0.0186,\n",
      "        -0.0061, -0.0300, -0.0023, -0.0399,  0.0403, -0.0098,  0.0191, -0.0197])\n",
      "Layer encoder.0.ln_2.bias: tensor([-0.0249, -0.0016, -0.0683,  0.0173,  0.0072,  0.0065, -0.0108,  0.0177,\n",
      "         0.0325, -0.0480,  0.0458, -0.0004,  0.0254, -0.0088,  0.0096,  0.0044,\n",
      "        -0.0288,  0.0137,  0.0395, -0.0076, -0.0145, -0.0861, -0.0166, -0.0572,\n",
      "        -0.0549,  0.0033, -0.0015,  0.0397,  0.0210,  0.0395, -0.0238, -0.0612,\n",
      "        -0.0165, -0.0071, -0.0099,  0.0477,  0.0738,  0.0320, -0.0208, -0.0310])\n",
      "Layer encoder.0.mlp.c_fc.weight: tensor([[-0.0039, -0.0217, -0.0172,  ..., -0.0230, -0.0028, -0.0159],\n",
      "        [-0.0088,  0.0017, -0.0048,  ..., -0.0225, -0.0221, -0.0083],\n",
      "        [ 0.0165, -0.0140,  0.0132,  ..., -0.0019,  0.0171,  0.0492],\n",
      "        ...,\n",
      "        [-0.0073,  0.0033,  0.0215,  ..., -0.0169, -0.0237, -0.0115],\n",
      "        [ 0.0179,  0.0237,  0.0110,  ..., -0.0102, -0.0164, -0.0189],\n",
      "        [-0.0122, -0.0070,  0.0027,  ..., -0.0041, -0.0123, -0.0120]])\n",
      "Layer encoder.0.mlp.c_fc.bias: tensor([ 0.0005, -0.0029,  0.0227, -0.0124, -0.0185, -0.0112,  0.0046,  0.0286,\n",
      "         0.0328,  0.0059, -0.0052,  0.0105,  0.0142, -0.0093, -0.0044,  0.0085,\n",
      "        -0.0222, -0.0138, -0.0108, -0.0163, -0.0135,  0.0022, -0.0230,  0.0116,\n",
      "        -0.0034, -0.0139,  0.0055,  0.0122,  0.0330,  0.0043, -0.0098,  0.0116,\n",
      "        -0.0286,  0.0062,  0.0041,  0.0420,  0.0171, -0.0002,  0.0189,  0.0340,\n",
      "        -0.0136, -0.0087,  0.0111, -0.0289, -0.0023,  0.0098, -0.0020, -0.0181,\n",
      "         0.0140, -0.0106, -0.0220,  0.0150, -0.0048, -0.0516,  0.0088,  0.0092,\n",
      "         0.0004,  0.0315, -0.0033,  0.0042, -0.0055, -0.0154, -0.0186, -0.0029,\n",
      "        -0.0089,  0.0008, -0.0009, -0.0110, -0.0134,  0.0168,  0.0083,  0.0167,\n",
      "         0.0026,  0.0012,  0.0009,  0.0095, -0.0032, -0.0110, -0.0247,  0.0035])\n",
      "Layer encoder.0.mlp.c_proj.weight: tensor([[-0.0030, -0.0099, -0.0041,  ...,  0.0088, -0.0071, -0.0092],\n",
      "        [-0.0062,  0.0182,  0.0165,  ...,  0.0059,  0.0113, -0.0036],\n",
      "        [-0.0099,  0.0208, -0.0039,  ...,  0.0061, -0.0103,  0.0165],\n",
      "        ...,\n",
      "        [-0.0126, -0.0135, -0.0056,  ...,  0.0013,  0.0025, -0.0016],\n",
      "        [-0.0246, -0.0147, -0.0311,  ..., -0.0067, -0.0001, -0.0134],\n",
      "        [-0.0292, -0.0186, -0.0264,  ..., -0.0011, -0.0118, -0.0072]])\n",
      "Layer encoder.0.mlp.c_proj.bias: tensor([-0.0056,  0.0099, -0.0437,  0.0010, -0.0352,  0.0275, -0.0128,  0.0067,\n",
      "         0.0374, -0.0507,  0.0674, -0.0066,  0.0300, -0.0268,  0.0012,  0.0054,\n",
      "        -0.0356,  0.0228,  0.0086, -0.0282, -0.0237, -0.0246, -0.0098, -0.0281,\n",
      "        -0.0684,  0.0166,  0.0558,  0.0157,  0.0212,  0.0036, -0.0159, -0.0292,\n",
      "         0.0025,  0.0016, -0.0305,  0.0164,  0.0543,  0.0111, -0.0194, -0.0269])\n",
      "Layer encoder.1.ln_1.weight: tensor([ 0.0156, -0.0316, -0.0308,  0.0202,  0.0160, -0.0089, -0.0039,  0.0474,\n",
      "        -0.0103,  0.0415, -0.0309,  0.0213, -0.0323, -0.0035, -0.0194, -0.0100,\n",
      "        -0.0062, -0.0269,  0.0027, -0.0307, -0.0072,  0.0079, -0.0023, -0.0123,\n",
      "        -0.0156, -0.0056, -0.0080, -0.0285,  0.0184,  0.0234,  0.0260,  0.0006,\n",
      "        -0.0018,  0.0130,  0.0134, -0.0076,  0.0324,  0.0204, -0.0240, -0.0448])\n",
      "Layer encoder.1.ln_1.bias: tensor([-0.0078,  0.0093, -0.0536,  0.0230, -0.0168,  0.0413, -0.0019,  0.0286,\n",
      "         0.0303, -0.0435,  0.0724, -0.0112,  0.0352, -0.0227,  0.0143,  0.0157,\n",
      "        -0.0385,  0.0480,  0.0200,  0.0026, -0.0174, -0.0645,  0.0067, -0.0209,\n",
      "        -0.0744,  0.0249,  0.0436,  0.0132,  0.0371,  0.0256, -0.0243, -0.0194,\n",
      "         0.0086, -0.0067, -0.0100,  0.0610,  0.0669,  0.0232, -0.0158, -0.0212])\n",
      "Layer encoder.1.attn.w_q.weight: tensor([[-0.0119, -0.0032, -0.0056,  ...,  0.0078, -0.0031,  0.0030],\n",
      "        [ 0.0037, -0.0032, -0.0078,  ..., -0.0094, -0.0071, -0.0041],\n",
      "        [ 0.0116, -0.0008,  0.0100,  ...,  0.0038,  0.0091,  0.0014],\n",
      "        ...,\n",
      "        [ 0.0105,  0.0059, -0.0080,  ..., -0.0063,  0.0099, -0.0181],\n",
      "        [-0.0030,  0.0289, -0.0044,  ..., -0.0024,  0.0078, -0.0030],\n",
      "        [-0.0102,  0.0003,  0.0041,  ...,  0.0043,  0.0006,  0.0121]])\n",
      "Layer encoder.1.attn.w_q.bias: tensor([-0.0058, -0.0071,  0.0118, -0.0049,  0.0006,  0.0134,  0.0188, -0.0018,\n",
      "         0.0148,  0.0058,  0.0086, -0.0029, -0.0011, -0.0023, -0.0029,  0.0081,\n",
      "         0.0039,  0.0033,  0.0030,  0.0080, -0.0016, -0.0104,  0.0004,  0.0085,\n",
      "        -0.0003,  0.0013, -0.0052,  0.0098, -0.0211, -0.0035, -0.0094,  0.0171,\n",
      "        -0.0047, -0.0025, -0.0019,  0.0041, -0.0100,  0.0005,  0.0137,  0.0023])\n",
      "Layer encoder.1.attn.w_k.weight: tensor([[-3.9142e-03,  2.0237e-03,  1.1929e-02,  ..., -3.5036e-03,\n",
      "          1.5478e-03, -2.5176e-03],\n",
      "        [-7.3336e-03, -2.4113e-03,  6.5282e-03,  ..., -1.5728e-02,\n",
      "         -1.8774e-02, -8.4933e-03],\n",
      "        [-6.5228e-03, -2.8719e-03,  5.0000e-04,  ..., -1.2302e-02,\n",
      "         -1.0751e-02, -3.8892e-03],\n",
      "        ...,\n",
      "        [ 8.9089e-03,  1.5649e-02,  6.1775e-03,  ..., -2.2771e-02,\n",
      "         -5.0606e-03, -1.0233e-02],\n",
      "        [ 2.4055e-05,  8.8073e-05,  7.6255e-03,  ..., -1.4944e-02,\n",
      "          2.6122e-03,  1.0547e-02],\n",
      "        [ 2.3180e-03, -5.0365e-03,  1.0606e-02,  ...,  8.4301e-03,\n",
      "         -5.0629e-05, -3.0814e-03]])\n",
      "Layer encoder.1.attn.w_k.bias: tensor([ 1.4279e-09, -3.0304e-09, -6.9849e-10,  1.4479e-09, -2.4738e-10,\n",
      "        -6.9485e-10,  2.4011e-09,  7.7125e-10,  2.7649e-10,  4.3947e-09,\n",
      "        -1.2933e-09,  1.9336e-09, -1.6735e-10,  3.0559e-10, -9.0768e-10,\n",
      "        -8.4583e-10, -5.5024e-10, -2.5357e-09, -4.1018e-10, -9.6406e-10,\n",
      "         4.0018e-10,  7.9308e-10, -1.8081e-09,  1.9718e-09,  2.3283e-10,\n",
      "        -1.3388e-09, -1.4043e-09, -9.1313e-10,  5.0932e-11,  1.0186e-09,\n",
      "         1.7462e-10,  2.1537e-09,  1.3970e-09, -4.6566e-10,  9.3132e-10,\n",
      "        -3.4925e-10, -9.3132e-10,  3.7253e-09,  9.3132e-10,  4.0745e-09])\n",
      "Layer encoder.1.attn.w_v.weight: tensor([[ 0.0046,  0.0140,  0.0072,  ..., -0.0056,  0.0064, -0.0098],\n",
      "        [-0.0101, -0.0154, -0.0044,  ..., -0.0006, -0.0030,  0.0082],\n",
      "        [ 0.0035,  0.0053, -0.0038,  ...,  0.0065, -0.0181, -0.0041],\n",
      "        ...,\n",
      "        [ 0.0021,  0.0036,  0.0026,  ..., -0.0094, -0.0005, -0.0053],\n",
      "        [ 0.0003, -0.0095,  0.0050,  ...,  0.0154,  0.0058,  0.0048],\n",
      "        [-0.0096, -0.0146, -0.0013,  ..., -0.0128,  0.0110,  0.0116]])\n",
      "Layer encoder.1.attn.w_v.bias: tensor([ 0.0010, -0.0011, -0.0163, -0.0337, -0.0307, -0.0223, -0.0280,  0.0130,\n",
      "         0.0191,  0.0471,  0.0236,  0.0067,  0.0238, -0.0230, -0.0163, -0.0088,\n",
      "         0.0254, -0.0131, -0.0769, -0.0119, -0.0461,  0.0144, -0.0106, -0.0529,\n",
      "        -0.0121,  0.0070,  0.0065, -0.0170, -0.0166,  0.0250,  0.0277,  0.0046,\n",
      "        -0.0075, -0.0200,  0.0253, -0.0062,  0.0159, -0.0011, -0.0289, -0.0002])\n",
      "Layer encoder.1.attn.c_proj.weight: tensor([[ 0.0116, -0.0079,  0.0308,  ...,  0.0056,  0.0122,  0.0169],\n",
      "        [ 0.0003, -0.0092, -0.0022,  ..., -0.0003, -0.0036,  0.0012],\n",
      "        [-0.0088, -0.0037,  0.0369,  ..., -0.0165, -0.0190, -0.0088],\n",
      "        ...,\n",
      "        [-0.0065,  0.0032,  0.0066,  ..., -0.0002, -0.0248, -0.0148],\n",
      "        [ 0.0157, -0.0009, -0.0056,  ...,  0.0223,  0.0073,  0.0011],\n",
      "        [-0.0028,  0.0010, -0.0149,  ..., -0.0002, -0.0094, -0.0064]])\n",
      "Layer encoder.1.attn.c_proj.bias: tensor([-0.0076,  0.0055, -0.0081, -0.0175, -0.0334,  0.0288, -0.0049, -0.0159,\n",
      "         0.0285,  0.0233,  0.0238,  0.0196,  0.0322,  0.0199, -0.0018, -0.0283,\n",
      "        -0.0203,  0.0033,  0.0165, -0.0282, -0.0034, -0.0041, -0.0128, -0.0312,\n",
      "        -0.0346,  0.0258,  0.0341, -0.0042,  0.0534, -0.0148,  0.0183, -0.0525,\n",
      "         0.0040, -0.0280,  0.0056,  0.0231, -0.0040, -0.0046,  0.0198, -0.0054])\n",
      "Layer encoder.1.ln_2.weight: tensor([ 0.0234, -0.0191, -0.0117,  0.0058,  0.0340, -0.0135,  0.0008,  0.0376,\n",
      "        -0.0150,  0.0338, -0.0332,  0.0109,  0.0168, -0.0230, -0.0196,  0.0055,\n",
      "        -0.0169, -0.0033,  0.0028, -0.0259, -0.0065,  0.0135, -0.0105, -0.0335,\n",
      "         0.0286,  0.0109, -0.0129, -0.0471,  0.0123,  0.0148,  0.0219, -0.0054,\n",
      "        -0.0100, -0.0087,  0.0155, -0.0292,  0.0233,  0.0319, -0.0313, -0.0128])\n",
      "Layer encoder.1.ln_2.bias: tensor([ 0.0103,  0.0191, -0.0172,  0.0006, -0.0207,  0.0162, -0.0084,  0.0092,\n",
      "         0.0267,  0.0014,  0.0124, -0.0003,  0.0218, -0.0115, -0.0142, -0.0155,\n",
      "        -0.0165,  0.0221, -0.0009, -0.0304, -0.0017, -0.0068, -0.0030, -0.0183,\n",
      "        -0.0443,  0.0203,  0.0362,  0.0127,  0.0366,  0.0142,  0.0019, -0.0504,\n",
      "         0.0038, -0.0089,  0.0030,  0.0269,  0.0184,  0.0178, -0.0072, -0.0201])\n",
      "Layer encoder.1.mlp.c_fc.weight: tensor([[ 0.0038,  0.0118, -0.0035,  ..., -0.0142,  0.0196, -0.0049],\n",
      "        [ 0.0093, -0.0211,  0.0056,  ...,  0.0173,  0.0173, -0.0102],\n",
      "        [ 0.0049,  0.0128, -0.0148,  ..., -0.0082,  0.0185,  0.0115],\n",
      "        ...,\n",
      "        [-0.0152, -0.0095,  0.0020,  ...,  0.0104, -0.0013,  0.0038],\n",
      "        [ 0.0006,  0.0064,  0.0075,  ...,  0.0194, -0.0164,  0.0248],\n",
      "        [-0.0210, -0.0414, -0.0046,  ...,  0.0053,  0.0179,  0.0070]])\n",
      "Layer encoder.1.mlp.c_fc.bias: tensor([-6.1858e-03, -1.7556e-02,  5.5691e-03,  7.9711e-04,  1.4372e-02,\n",
      "         1.2396e-02, -8.9978e-03,  8.7260e-03,  1.5982e-02,  2.6307e-02,\n",
      "         3.7567e-02,  8.6718e-03,  9.4493e-03,  1.8400e-02,  1.3962e-03,\n",
      "         5.4829e-03,  1.8006e-02,  1.6671e-02,  4.6245e-03, -1.1284e-02,\n",
      "         1.3453e-02,  3.2085e-03, -4.2166e-03, -1.6593e-02,  6.8656e-03,\n",
      "        -1.4512e-02,  5.1341e-03,  1.3396e-02,  5.5969e-03, -8.7552e-05,\n",
      "        -1.4804e-02,  2.9428e-03,  1.7674e-03, -7.5514e-03,  1.7524e-02,\n",
      "         2.4045e-02, -1.4801e-03, -2.4986e-02, -1.6805e-02,  3.2359e-03,\n",
      "         5.2434e-03,  6.8690e-03, -2.8941e-03, -3.1743e-02,  1.5804e-02,\n",
      "         1.5259e-02,  2.9341e-03,  1.7225e-02,  1.9375e-02, -1.0236e-02,\n",
      "         2.7222e-03, -7.3361e-03, -1.2676e-02,  5.8375e-03,  4.3613e-03,\n",
      "         1.5744e-03, -6.0673e-03, -2.5826e-03, -6.9185e-03,  6.1850e-03,\n",
      "        -5.7158e-04, -6.3978e-03, -2.2616e-02,  1.0557e-02,  1.5245e-02,\n",
      "        -1.7183e-02,  3.9114e-03, -7.6432e-04,  3.3770e-03, -2.1084e-02,\n",
      "        -2.0829e-03, -3.1680e-02,  2.4021e-02, -1.8897e-02,  2.2404e-03,\n",
      "         1.3195e-02, -8.7900e-05, -7.7623e-03, -7.7611e-03, -1.7783e-02])\n",
      "Layer encoder.1.mlp.c_proj.weight: tensor([[-0.0050, -0.0082,  0.0090,  ...,  0.0013,  0.0049, -0.0129],\n",
      "        [-0.0018,  0.0016, -0.0001,  ..., -0.0024,  0.0025, -0.0131],\n",
      "        [ 0.0030, -0.0159, -0.0069,  ...,  0.0009,  0.0010,  0.0149],\n",
      "        ...,\n",
      "        [ 0.0061, -0.0016,  0.0040,  ...,  0.0074, -0.0034,  0.0046],\n",
      "        [-0.0104, -0.0004, -0.0094,  ..., -0.0108, -0.0054, -0.0003],\n",
      "        [-0.0035, -0.0028, -0.0005,  ..., -0.0169,  0.0003, -0.0151]])\n",
      "Layer encoder.1.mlp.c_proj.bias: tensor([ 0.0122,  0.0137, -0.0257, -0.0043, -0.0225,  0.0379,  0.0128,  0.0042,\n",
      "         0.0224, -0.0098, -0.0646, -0.0026,  0.0345, -0.0379,  0.0283, -0.0225,\n",
      "         0.0082, -0.0240, -0.0265, -0.0160, -0.0148,  0.0076, -0.0038, -0.0303,\n",
      "         0.0042,  0.0001,  0.0349,  0.0275, -0.0057,  0.0109,  0.0018, -0.0359,\n",
      "        -0.0198,  0.0117, -0.0023,  0.0175,  0.0302, -0.0016, -0.0088, -0.0400])\n",
      "Layer classif.fc.0.weight: tensor([[-1.2894e-02, -1.6260e-02, -1.0945e-04,  ...,  8.0079e-03,\n",
      "         -3.1461e-03,  3.3243e-03],\n",
      "        [-3.7713e-03,  6.9283e-04,  3.3643e-04,  ..., -4.0379e-03,\n",
      "         -2.0759e-03, -9.4052e-03],\n",
      "        [-2.8547e-03, -1.5374e-03, -9.2060e-03,  ..., -1.2001e-02,\n",
      "         -2.6028e-03, -4.3748e-03],\n",
      "        ...,\n",
      "        [-4.5653e-03,  3.0962e-03,  1.0216e-03,  ..., -2.8785e-03,\n",
      "         -4.2004e-03,  1.6286e-03],\n",
      "        [ 4.8035e-03,  1.2563e-02,  1.6137e-02,  ...,  1.3825e-02,\n",
      "         -1.8460e-03, -2.1768e-03],\n",
      "        [-4.8722e-03, -7.7246e-04, -3.2470e-05,  ...,  3.5549e-04,\n",
      "         -6.5904e-03, -8.1443e-03]])\n",
      "Layer classif.fc.0.bias: tensor([-9.5247e-03,  7.6412e-03,  2.6889e-03,  2.0930e-03,  4.6773e-03,\n",
      "         1.2203e-03,  4.9423e-03,  2.7575e-03, -1.1059e-03, -1.0734e-02,\n",
      "        -8.1504e-03, -6.9674e-03, -3.8962e-03,  6.0730e-03,  1.0424e-02,\n",
      "         1.7164e-03, -5.7743e-04, -1.1876e-02, -4.0855e-03, -2.7784e-03,\n",
      "         4.1316e-03, -1.3179e-03,  3.2451e-03,  6.4987e-03, -2.1318e-03,\n",
      "        -7.5400e-04,  1.0727e-03, -1.5195e-02, -8.7070e-03, -7.1540e-03,\n",
      "        -4.3541e-03,  2.2842e-03,  1.7546e-03,  1.6072e-03, -1.8880e-03,\n",
      "        -8.5135e-03,  3.3907e-03,  5.2137e-03, -8.2176e-03, -6.2440e-03,\n",
      "        -1.4309e-03, -2.3197e-04,  9.6454e-03,  7.2001e-04,  1.1221e-02,\n",
      "         5.3213e-03, -1.4561e-03,  5.0367e-03, -3.5795e-03,  8.9019e-04,\n",
      "         2.8434e-03, -2.1480e-03, -4.5940e-03,  1.8476e-04, -3.8359e-03,\n",
      "         3.3227e-03,  3.5947e-03,  4.2179e-03, -1.0686e-03, -6.1421e-04,\n",
      "        -8.1198e-03, -1.8896e-03,  3.6336e-03,  1.8637e-03,  1.4802e-03,\n",
      "        -4.1135e-03, -5.4025e-03,  2.3131e-04, -3.2451e-03, -5.2929e-03,\n",
      "        -7.9573e-03, -3.8939e-03,  7.7464e-03, -2.5687e-03, -2.0407e-03,\n",
      "        -2.8883e-03, -3.0612e-03, -4.1305e-03, -1.1602e-02,  2.7665e-03,\n",
      "         5.0423e-03, -1.0928e-04,  4.8184e-03,  5.6939e-03, -2.9044e-03,\n",
      "         1.3002e-02,  2.0056e-03, -3.3323e-03,  5.2653e-03, -1.6629e-03,\n",
      "        -7.1241e-03,  2.3771e-03, -1.3486e-03,  1.5267e-03, -5.9245e-03,\n",
      "         2.6940e-03,  5.6893e-03, -6.0740e-04, -4.0386e-03, -1.8092e-03,\n",
      "         1.7545e-03,  3.7644e-03,  3.4743e-04, -3.4912e-04, -5.3341e-04,\n",
      "        -1.7961e-03,  5.0595e-03,  3.7564e-03,  7.0688e-03,  4.0525e-03,\n",
      "        -8.3232e-03,  5.8257e-03,  5.5737e-03, -1.5989e-03, -6.6309e-04,\n",
      "        -4.7622e-03,  4.1707e-03, -4.0693e-03, -1.1740e-03, -7.7191e-03,\n",
      "         1.3687e-02, -9.4152e-03,  4.4565e-03, -1.7634e-03, -2.7361e-03,\n",
      "         9.4324e-03, -2.8258e-03,  2.3083e-03,  2.9133e-03, -4.7854e-03,\n",
      "        -1.0232e-02, -3.9388e-04,  2.6751e-03, -2.3079e-03,  1.1827e-03,\n",
      "        -1.1194e-02, -9.5532e-03,  1.8653e-03,  1.3605e-03,  5.9580e-03,\n",
      "         5.8339e-03, -7.3083e-03,  7.2214e-04, -7.4976e-03,  6.7576e-03,\n",
      "         2.7931e-03, -1.0120e-02,  3.7311e-03,  1.0459e-02,  3.1109e-03,\n",
      "        -2.1505e-03,  4.3057e-04,  6.1725e-03, -4.9654e-03, -9.7686e-03,\n",
      "         2.8868e-03,  4.6639e-03, -2.9865e-03, -8.2318e-03,  5.0263e-03,\n",
      "        -3.8073e-04,  7.4251e-03, -1.0604e-03,  7.4836e-03, -1.9605e-02,\n",
      "        -5.6470e-03,  1.9891e-03,  5.0455e-03, -3.4873e-03, -2.6742e-03,\n",
      "         1.2411e-03, -1.2107e-03, -7.2118e-03,  4.7874e-03, -1.0006e-03,\n",
      "        -4.2823e-05,  6.1723e-03, -9.2714e-03, -2.9113e-03,  4.8271e-03,\n",
      "         6.0897e-03,  5.3758e-03, -1.8575e-03, -9.2418e-03, -1.5198e-03,\n",
      "         5.3994e-03, -5.4034e-03,  1.0007e-02, -3.6282e-03, -3.8606e-03,\n",
      "         2.7179e-03, -1.9820e-03, -2.0193e-03, -5.0693e-03, -2.2511e-03,\n",
      "        -2.7143e-03, -8.9442e-03,  6.7844e-03,  4.7748e-03, -3.9578e-03,\n",
      "        -1.5646e-03,  7.2134e-03, -4.3624e-03,  7.1016e-03,  5.6257e-03,\n",
      "        -4.7404e-03,  2.6722e-03, -1.3226e-03, -6.7679e-03,  6.9985e-04,\n",
      "         3.5989e-03, -7.0450e-04, -4.8509e-03,  6.1057e-03, -5.8733e-04,\n",
      "         6.0660e-03, -8.3206e-03,  1.5960e-03,  4.1995e-03, -2.8970e-03,\n",
      "        -7.0754e-03, -4.3634e-03, -1.1036e-02,  5.0021e-04, -1.9902e-04,\n",
      "         4.3004e-03,  8.4734e-03,  1.8017e-03, -6.1786e-03, -2.8645e-03,\n",
      "         9.2988e-04,  6.5346e-03, -6.2035e-04, -2.7370e-03,  9.3632e-04,\n",
      "         5.8752e-05, -1.7709e-03,  3.0417e-03,  7.6043e-03,  3.2931e-03,\n",
      "         5.3000e-05,  5.3003e-03,  1.2739e-03, -2.3045e-03, -1.5748e-03,\n",
      "         1.7094e-03, -1.3691e-02, -2.1009e-03,  4.9311e-03,  1.8207e-03,\n",
      "        -7.5619e-03,  4.0430e-03,  2.5045e-03,  1.7770e-03,  1.8742e-03,\n",
      "         3.3867e-03])\n",
      "Layer classif.fc.3.weight: tensor([[-9.4009e-03,  1.5655e-05, -1.1426e-02,  ..., -2.5508e-03,\n",
      "          3.6793e-03,  1.5543e-02],\n",
      "        [ 9.2631e-03,  6.9857e-04,  7.4495e-03,  ...,  6.6583e-03,\n",
      "         -1.3204e-04, -1.1736e-02],\n",
      "        [-1.9950e-02,  3.1651e-03, -3.5177e-02,  ..., -1.2931e-02,\n",
      "         -2.4246e-02,  1.5921e-03],\n",
      "        ...,\n",
      "        [-1.0862e-02,  1.7426e-03, -7.5629e-03,  ...,  5.1516e-04,\n",
      "          1.0292e-02, -4.0953e-03],\n",
      "        [ 6.2577e-04, -3.9793e-03,  1.9359e-03,  ..., -2.1144e-03,\n",
      "          1.9047e-03, -3.5437e-03],\n",
      "        [-1.1816e-04,  1.4362e-04, -2.8345e-05,  ...,  5.2261e-05,\n",
      "          9.5336e-05, -1.6242e-04]])\n",
      "Layer classif.fc.3.bias: tensor([ 6.3108e-03, -5.8123e-03, -1.1589e-02, -4.3346e-05,  6.0508e-05,\n",
      "         8.1042e-03, -1.3094e-03, -6.1388e-03,  2.9828e-03,  4.1537e-03,\n",
      "        -1.9108e-03,  5.3359e-04, -8.9483e-03,  2.0912e-03, -1.0589e-02,\n",
      "        -3.6575e-02, -2.3843e-05, -2.0849e-02, -2.3771e-03,  1.2948e-04,\n",
      "        -6.4544e-04,  6.1012e-03,  4.9537e-03, -1.4867e-02,  7.5137e-03,\n",
      "         1.0533e-02, -2.0991e-02, -5.3898e-03,  1.1629e-03, -1.3832e-03,\n",
      "        -1.7372e-03,  8.1595e-05])\n",
      "Layer classif.fc.6.weight: tensor([[ 0.0109, -0.0195,  0.1738,  0.0318, -0.0775, -0.1161, -0.0190,  0.0773,\n",
      "          0.0079,  0.1517, -0.0139, -0.0471, -0.0496,  0.0429, -0.1346,  0.0721,\n",
      "         -0.0421, -0.0385,  0.0263, -0.1187, -0.1087, -0.0194, -0.0441, -0.0966,\n",
      "          0.1374, -0.0474, -0.0264, -0.0246, -0.0606,  0.0425,  0.0477, -0.0509]])\n",
      "Layer classif.fc.6.bias: tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "for name, param in mdl.named_parameters():\n",
    "    if param is not None:\n",
    "        print(f'Layer {name}: {param.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TENSORBOARD SAVING HISTOGRAM GRAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in mdl.named_parameters():\n",
    "    if param is not None:\n",
    "        # SAVING NAME, GRAD, EPOCH\n",
    "        writer.add_histogram(f'{name}.grad', param.grad, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WANDB GRADIENT SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:96egw02t) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e449d571a2d946a6b775655821b7d570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.074 MB of 0.074 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sleek-morning-1</strong> at: <a href='https://wandb.ai/garcesote-upna-universidad/gradient_tracking/runs/96egw02t' target=\"_blank\">https://wandb.ai/garcesote-upna-universidad/gradient_tracking/runs/96egw02t</a><br/> View project at: <a href='https://wandb.ai/garcesote-upna-universidad/gradient_tracking' target=\"_blank\">https://wandb.ai/garcesote-upna-universidad/gradient_tracking</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241018_141235-96egw02t\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:96egw02t). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jaulab\\Desktop\\deepAAD_project\\notebooks\\wandb\\run-20241021_110524-y15lkulw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/garcesote-upna-universidad/gradient_tracking/runs/y15lkulw' target=\"_blank\">celestial-meadow-2</a></strong> to <a href='https://wandb.ai/garcesote-upna-universidad/gradient_tracking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/garcesote-upna-universidad/gradient_tracking' target=\"_blank\">https://wandb.ai/garcesote-upna-universidad/gradient_tracking</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/garcesote-upna-universidad/gradient_tracking/runs/y15lkulw' target=\"_blank\">https://wandb.ai/garcesote-upna-universidad/gradient_tracking/runs/y15lkulw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/garcesote-upna-universidad/gradient_tracking/runs/y15lkulw?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2498d0ad0c0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='gradient_tracking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in mdl.named_parameters():\n",
    "    if param.grad is not None and 'bias' not in name:\n",
    "        # detach that eliminates property of the tensor of requiring grad\n",
    "        wandb.log({f\"{name}_grad\": wandb.Histogram(param.cpu().detach().numpy()), \"epoch\": 0}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed.shallownet.0.weight\n",
      "embed.shallownet.1.weight\n",
      "embed.shallownet.2.weight\n",
      "embed.projection.weight\n",
      "encoder.0.ln_1.weight\n",
      "encoder.0.attn.w_q.weight\n",
      "encoder.0.attn.w_k.weight\n",
      "encoder.0.attn.w_v.weight\n",
      "encoder.0.attn.c_proj.weight\n",
      "encoder.0.ln_2.weight\n",
      "encoder.0.mlp.c_fc.weight\n",
      "encoder.0.mlp.c_proj.weight\n",
      "encoder.1.ln_1.weight\n",
      "encoder.1.attn.w_q.weight\n",
      "encoder.1.attn.w_k.weight\n",
      "encoder.1.attn.w_v.weight\n",
      "encoder.1.attn.c_proj.weight\n",
      "encoder.1.ln_2.weight\n",
      "encoder.1.mlp.c_fc.weight\n",
      "encoder.1.mlp.c_proj.weight\n",
      "classif.fc.0.weight\n",
      "classif.fc.3.weight\n",
      "classif.fc.6.weight\n"
     ]
    }
   ],
   "source": [
    "for name, param in mdl.named_parameters():\n",
    "    if param.grad is not None and 'bias' not in name:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_layers = ['classif.fc.0.weight', \n",
    "                  'classif.fc.6.weight', \n",
    "                  'embed.shallownet.0.weight',\n",
    "                  'embed.shallownet.2.weight',\n",
    "                  'encoder.0.attn.w_q.weight',\n",
    "                  'encoder.3.attn.w_q.weight',\n",
    "                  'encoder.0.mlp.c_fc.weight',\n",
    "                  'encoder.3.mlp.c_fc.weight',\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in mdl.named_parameters():\n",
    "    if param.grad is not None and name in desired_layers:\n",
    "        # detach that eliminates property of the tensor of requiring grad\n",
    "        wandb.log({f\"{name}_grad\": wandb.Histogram(param.cpu().detach().numpy()), \"epoch\": 0}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WANDB WATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datasets import CustomDataset\n",
    "from utils.functional import get_data_path\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = get_data_path('C:/Users/jaulab/Desktop/AAD/Data', 'fulsang', filt=False)\n",
    "dataset = CustomDataset('fulsang', data_path, 'train', 'S1', 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mdl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmdl\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(mdl\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-06\u001b[39m, weight_decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-04\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mdl' is not defined"
     ]
    }
   ],
   "source": [
    "mdl.to(device)\n",
    "optimizer = torch.optim.Adam(mdl.parameters(), lr=1e-06, weight_decay = 1e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:qp5q1syh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e69b52e2c134dc5ad013c5d059977ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.006 MB of 0.006 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">rich-grass-7</strong> at: <a href='https://wandb.ai/garcesote-upna-universidad/gradient_tracking/runs/qp5q1syh' target=\"_blank\">https://wandb.ai/garcesote-upna-universidad/gradient_tracking/runs/qp5q1syh</a><br/> View project at: <a href='https://wandb.ai/garcesote-upna-universidad/gradient_tracking' target=\"_blank\">https://wandb.ai/garcesote-upna-universidad/gradient_tracking</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241021_114701-qp5q1syh\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:qp5q1syh). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\jaulab\\Desktop\\deepAAD_project\\notebooks\\wandb\\run-20241021_114858-r4r3nlkg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/garcesote-upna-universidad/gradient_tracking/runs/r4r3nlkg' target=\"_blank\">expert-sponge-8</a></strong> to <a href='https://wandb.ai/garcesote-upna-universidad/gradient_tracking' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/garcesote-upna-universidad/gradient_tracking' target=\"_blank\">https://wandb.ai/garcesote-upna-universidad/gradient_tracking</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/garcesote-upna-universidad/gradient_tracking/runs/r4r3nlkg' target=\"_blank\">https://wandb.ai/garcesote-upna-universidad/gradient_tracking/runs/r4r3nlkg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: -0.10746944695711136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: -0.03581579402089119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.10303233563899994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: -0.17529068887233734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.03303400054574013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: -0.12475737184286118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: -0.01291625201702118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[91], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m epoch_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm_loader):\n\u001b[1;32m---> 14\u001b[0m     eeg \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meeg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     stima \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstima\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m     17\u001b[0m     preds, loss \u001b[38;5;241m=\u001b[39m mdl(eeg, targets \u001b[38;5;241m=\u001b[39m stima)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wandb.init(project='gradient_tracking')\n",
    "wandb.watch(models = mdl, log='all', log_freq=len(data_loader))\n",
    "\n",
    "max_epoch = 5\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "\n",
    "    tqdm_loader = tqdm.tqdm(data_loader, desc=f'Epoch: {epoch}', leave = False, mininterval=0.5)\n",
    "    \n",
    "    epoch_losses = []\n",
    "\n",
    "    for batch_idx, data in enumerate(tqdm_loader):\n",
    "\n",
    "        eeg = data['eeg'].to(device, dtype=torch.float)\n",
    "        stima = data['stima'].to(device, dtype=torch.float)\n",
    "\n",
    "        preds, loss = mdl(eeg, targets = stima)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss)\n",
    "\n",
    "    print(f'loss: {torch.mean(loss).item()}')\n",
    "    wandb.log({'train_loss': -torch.mean(loss).item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.dnn import FCNN, CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = FCNN(n_hidden=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temporal.0.weight\n",
      "temporal.0.bias\n",
      "temporal.1.weight\n",
      "temporal.1.bias\n",
      "spatial.0.weight\n",
      "spatial.0.bias\n",
      "spatial.1.weight\n",
      "spatial.1.bias\n",
      "depthwise.0.weight\n",
      "depthwise.0.bias\n",
      "depthwise.1.weight\n",
      "depthwise.1.bias\n",
      "depthwise.2.weight\n",
      "depthwise.2.bias\n",
      "classifier.1.weight\n",
      "classifier.1.bias\n"
     ]
    }
   ],
   "source": [
    "for layer, param in mdl.named_parameters():\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64]), None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((64,64,50))\n",
    "preds, loss = mdl(x)\n",
    "preds.shape, loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSS_Enviroment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
